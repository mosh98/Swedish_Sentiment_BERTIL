# Swedish_Sentiment_BERTIL

I named it BERT_IL becuase its Swedish ;)

I wrote a small paper on how to fine tune KB BERT model for sentiemnt analysis using around ~15000 examples. This  was an exploratory investigation for current swedish BERT model(released 2020).

The results show KB-BERT performs with a 60% accuracy when it comes to sentiment analysis. Which is very poor however there were a few papers that depicts that if bert is trained with dataset containing around ~20k examples, it could perform very well.


Bert performing results from this paper
![graph](https://github.com/mosh98/Swedish_Sentiment_BERTIL/blob/main/xxx.png)

### F1 score:  0.5711702412679611

### Precision Score:  0.6927536231884058

### Recall Score:  0.6867816091954023


You can find the paper here.
 ![mm](https://github.com/mosh98/Swedish_Sentiment_BERTIL/blob/main/Transformer_paper.pdf)
 
